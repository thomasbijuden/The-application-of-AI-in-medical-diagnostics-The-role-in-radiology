# Reliable and Explainable AI for Chest X-ray Diagnosis

This repository contains the complete experimental pipeline and validated results for the Master’s thesis:

*“The Application of Artificial Intelligence in Medical Diagnostics: The Role of AI in Radiology.”*

The project evaluates deep learning systems for chest X-ray interpretation with a specific focus on *diagnostic reliability, probability calibration, and explainability*, rather than raw classification accuracy alone.

---

## Dataset

This study uses the *CheXpert v1.0 (small)* dataset released by the Stanford Machine Learning Group.

CheXpert is a large-scale chest X-ray dataset with expert-annotated labels for multiple thoracic conditions. The small version is the official research subset designed for reproducible machine-learning experiments.

Dataset access:  
https://stanfordmlgroup.github.io/competitions/chexpert/

The dataset is *not included in this repository* due to licensing and redistribution restrictions. All code in this repository is written to load the dataset after it has been obtained from Stanford.

---

## Project Scope

The system is trained and evaluated on five thoracic conditions:

* Atelectasis  
* Cardiomegaly  
* Consolidation  
* Edema  
* Pleural Effusion  

The model is analysed as a *probabilistic, explainable decision-support tool* rather than an autonomous diagnostic system.

---

## Repository Structure

### /colab/
Contains the full executable Google Colab notebook:

ThomasWorking.ipynb

This notebook implements the entire experimental pipeline, including:
- Dataset loading and preprocessing  
- Patient-level splitting and leakage checks  
- CNN training and validation  
- AUROC and PR-AUC computation  
- Probability calibration  
- Reliability diagrams  
- Selective prediction (abstention) analysis  
- Error analysis (false positives and false negatives)  
- Grad-CAM explainability  

All results reported in the thesis were generated from this notebook.

---

### /Thesis Results/
Contains CSV files that correspond directly to the quantitative tables in Chapter 4 of the thesis:

| File | Purpose |
|------|--------|
| RO1_AUC_table.csv | AUROC and PR-AUC per pathology |
| RO1_threshold_table_0.5.csv | Sensitivity and specificity at fixed threshold |
| RO1_triage_thresholds.csv | Clinically tuned operating points |
| RO2_ECE_before_after.csv | Calibration results (Expected Calibration Error) |

These tables provide full transparency for all reported numerical results.

Contains visual outputs generated by the notebook, including:
- Reliability diagrams  etc

These figures are referenced directly in Chapter 4 of the thesis.

---

## Reproducibility

All experiments can be reproduced by:

1. Downloading CheXpert-v1.0-small from Stanford  
2. Uploading it to Google Drive or Colab storage  
3. Running ThomasWorking.ipynb in Google Colab with GPU enabled  

The notebook contains all preprocessing, training, evaluation, and visualisation steps required to regenerate the reported results.

---

## Academic Integrity

This repository contains the complete experimental evidence supporting the thesis claims. All tables, figures, and metrics in the dissertation are derived from the files in this repository.

The CheXpert dataset is referenced but not redistributed, in accordance with Stanford’s licensing terms.
